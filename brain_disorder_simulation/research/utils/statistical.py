"""
í†µê³„ ë¶„ì„ ë„êµ¬

ì˜ë£Œ ì—°êµ¬ë¥¼ ìœ„í•œ í†µê³„ ë¶„ì„ ê¸°ëŠ¥
- Seed Sweep (ë‹¤ì¤‘ ì‹œë®¬ë ˆì´ì…˜)
- í†µì œ ê·¸ë£¹ ë¹„êµ
- í†µê³„ ê²€ì • (t-test, ANOVA)
- íš¨ê³¼ í¬ê¸° (Cohen's d)
- ì‹ ë¢°êµ¬ê°„ ê³„ì‚°

ì—°êµ¬ ê·¼ê±°:
- Cohen (1988) - Statistical power analysis
- Cumming (2012) - Understanding the new statistics
- Lakens (2013) - Calculating and reporting effect sizes

ì°¸ê³  ë¬¸í—Œ:
- Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.)
- Cumming, G. (2012). Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis
- Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science

Author: GNJz (Qquarts)
Version: 1.0.0
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from scipy import stats
import warnings
warnings.filterwarnings('ignore')


@dataclass
class StatisticalResult:
    """í†µê³„ ë¶„ì„ ê²°ê³¼"""
    t_statistic: float
    p_value: float
    cohens_d: float
    confidence_interval: Tuple[float, float]
    effect_size_interpretation: str
    mean_diff: float
    std_diff: float
    n1: int
    n2: int
    df: int


@dataclass
class SeedSweepResult:
    """Seed Sweep ê²°ê³¼"""
    results: List[Dict[str, Any]]
    n_seeds: int
    mean_values: Dict[str, float]
    std_values: Dict[str, float]
    ci_95: Dict[str, Tuple[float, float]]
    distribution_stats: Dict[str, Dict[str, float]]


class StatisticalAnalyzer:
    """
    í†µê³„ ë¶„ì„ ë„êµ¬
    
    ê¸°ëŠ¥:
    - ë‹¤ì¤‘ ì‹œë®¬ë ˆì´ì…˜ (Seed Sweep)
    - í†µì œ ê·¸ë£¹ ë¹„êµ
    - í†µê³„ ê²€ì • (t-test, ANOVA)
    - íš¨ê³¼ í¬ê¸° (Cohen's d)
    - ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
    
    ì—°êµ¬ ê·¼ê±°:
    - ì„ìƒ ì—°êµ¬ì—ì„œ í‘œì¤€ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” í†µê³„ ë°©ë²•
    - íš¨ê³¼ í¬ê¸°ëŠ” Cohen (1988) ê¸°ì¤€ ì‚¬ìš©
    - ì‹ ë¢°êµ¬ê°„ì€ 95% ê¸°ì¤€
    """
    
    def __init__(self):
        """í†µê³„ ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        pass
    
    def seed_sweep(self, 
                   simulator_func,
                   n_seeds: int = 100,
                   seed_start: int = 0,
                   **simulator_params) -> SeedSweepResult:
        """
        ë‹¤ì¤‘ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (Seed Sweep)
        
        ì—°êµ¬ ê·¼ê±°:
        - ì‹œë®¬ë ˆì´ì…˜ì˜ ì¬í˜„ì„± ê²€ì¦
        - ê²°ê³¼ì˜ ë¶„í¬ ë¶„ì„
        - í†µê³„ì  ì‹ ë¢°ë„ í™•ë³´
        
        Args:
            simulator_func: ì‹œë®¬ë ˆì´í„° í•¨ìˆ˜ ë˜ëŠ” í´ë˜ìŠ¤
            n_seeds: ì‹œë“œ ê°œìˆ˜
            seed_start: ì‹œì‘ ì‹œë“œ ë²ˆí˜¸
            **simulator_params: ì‹œë®¬ë ˆì´í„° íŒŒë¼ë¯¸í„°
        
        Returns:
            Seed Sweep ê²°ê³¼
        """
        results = []
        
        print(f"ğŸ”„ Seed Sweep ì‹¤í–‰ ì¤‘... (n={n_seeds})")
        
        for i, seed in enumerate(range(seed_start, seed_start + n_seeds)):
            try:
                # ì‹œë®¬ë ˆì´í„° ì‹¤í–‰
                if callable(simulator_func):
                    # í•¨ìˆ˜ì¸ ê²½ìš°
                    result = simulator_func(seed=seed, **simulator_params)
                else:
                    # í´ë˜ìŠ¤ì¸ ê²½ìš°
                    simulator = simulator_func(seed=seed, **simulator_params)
                    result = simulator.simulate_full_assessment()
                
                results.append(result)
                
                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if (i + 1) % 20 == 0:
                    print(f"  ì§„í–‰: {i + 1}/{n_seeds} ({100 * (i + 1) / n_seeds:.1f}%)")
                    
            except Exception as e:
                print(f"âš ï¸  Seed {seed} ì‹¤íŒ¨: {e}")
                continue
        
        print(f"âœ… Seed Sweep ì™„ë£Œ: {len(results)}/{n_seeds} ì„±ê³µ")
        
        # í†µê³„ ê³„ì‚°
        if not results:
            raise ValueError("ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        # ê²°ê³¼ì—ì„œ ìˆ«ì ê°’ ì¶”ì¶œ
        numeric_keys = self._extract_numeric_keys(results[0])
        
        mean_values = {}
        std_values = {}
        ci_95 = {}
        distribution_stats = {}
        
        for key in numeric_keys:
            values = [self._get_nested_value(r, key) for r in results]
            values = [v for v in values if v is not None and not np.isnan(v) and not np.isinf(v)]
            
            if len(values) > 0:
                mean_values[key] = np.mean(values)
                std_values[key] = np.std(values)
                ci_95[key] = self._calculate_confidence_interval(values, confidence=0.95)
                
                # ë¶„í¬ í†µê³„
                distribution_stats[key] = {
                    'min': np.min(values),
                    'max': np.max(values),
                    'median': np.median(values),
                    'q25': np.percentile(values, 25),
                    'q75': np.percentile(values, 75),
                    'skewness': stats.skew(values) if len(values) > 2 else 0.0,
                    'kurtosis': stats.kurtosis(values) if len(values) > 2 else 0.0
                }
        
        return SeedSweepResult(
            results=results,
            n_seeds=len(results),
            mean_values=mean_values,
            std_values=std_values,
            ci_95=ci_95,
            distribution_stats=distribution_stats
        )
    
    def compare_groups(self,
                      group1: List[Dict[str, Any]],
                      group2: List[Dict[str, Any]],
                      metric_key: str,
                      alpha: float = 0.05) -> StatisticalResult:
        """
        ë‘ ê·¸ë£¹ ë¹„êµ
        
        ì—°êµ¬ ê·¼ê±°:
        - ë…ë¦½ í‘œë³¸ t-test ì‚¬ìš©
        - íš¨ê³¼ í¬ê¸°ëŠ” Cohen's d
        - 95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        
        Args:
            group1: ì²« ë²ˆì§¸ ê·¸ë£¹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            group2: ë‘ ë²ˆì§¸ ê·¸ë£¹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            metric_key: ë¹„êµí•  ì§€í‘œ í‚¤ (ì˜ˆ: 'energy', 'motivation')
            alpha: ìœ ì˜ìˆ˜ì¤€ (ê¸°ë³¸ê°’: 0.05)
        
        Returns:
            í†µê³„ ë¶„ì„ ê²°ê³¼
        """
        # ê°’ ì¶”ì¶œ
        values1 = [self._get_nested_value(r, metric_key) for r in group1]
        values2 = [self._get_nested_value(r, metric_key) for r in group2]
        
        # NaN, Inf ì œê±°
        values1 = [v for v in values1 if v is not None and not np.isnan(v) and not np.isinf(v)]
        values2 = [v for v in values2 if v is not None and not np.isnan(v) and not np.isinf(v)]
        
        if len(values1) < 2 or len(values2) < 2:
            raise ValueError(f"ê·¸ë£¹ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: group1={len(values1)}, group2={len(values2)}")
        
        values1 = np.array(values1)
        values2 = np.array(values2)
        
        # t-test
        t_stat, p_value = stats.ttest_ind(values1, values2)
        
        # Cohen's d
        cohens_d = self._calculate_cohens_d(values1, values2)
        
        # íš¨ê³¼ í¬ê¸° í•´ì„
        effect_size_interpretation = self._interpret_effect_size(cohens_d)
        
        # í‰ê·  ì°¨ì´
        mean_diff = np.mean(values1) - np.mean(values2)
        
        # í‘œì¤€í¸ì°¨ ì°¨ì´
        std_diff = np.std(values1) - np.std(values2)
        
        # ììœ ë„
        df = len(values1) + len(values2) - 2
        
        # ì‹ ë¢°êµ¬ê°„
        ci = self._calculate_confidence_interval_diff(values1, values2, confidence=1 - alpha)
        
        return StatisticalResult(
            t_statistic=t_stat,
            p_value=p_value,
            cohens_d=cohens_d,
            confidence_interval=ci,
            effect_size_interpretation=effect_size_interpretation,
            mean_diff=mean_diff,
            std_diff=std_diff,
            n1=len(values1),
            n2=len(values2),
            df=df
        )
    
    def compare_multiple_groups(self,
                                groups: Dict[str, List[Dict[str, Any]]],
                                metric_key: str,
                                alpha: float = 0.05) -> Dict[str, Any]:
        """
        ë‹¤ì¤‘ ê·¸ë£¹ ë¹„êµ (ANOVA)
        
        ì—°êµ¬ ê·¼ê±°:
        - ì¼ì› ë¶„ì‚°ë¶„ì„ (One-way ANOVA)
        - ì‚¬í›„ ê²€ì • (Tukey HSD)
        
        Args:
            groups: ê·¸ë£¹ ì´ë¦„ê³¼ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë”•ì…”ë„ˆë¦¬
            metric_key: ë¹„êµí•  ì§€í‘œ í‚¤
            alpha: ìœ ì˜ìˆ˜ì¤€
        
        Returns:
            ANOVA ê²°ê³¼
        """
        # ê°’ ì¶”ì¶œ
        group_values = {}
        for group_name, group_results in groups.items():
            values = [self._get_nested_value(r, metric_key) for r in group_results]
            values = [v for v in values if v is not None and not np.isnan(v) and not np.isinf(v)]
            if len(values) > 0:
                group_values[group_name] = np.array(values)
        
        if len(group_values) < 2:
            raise ValueError("ê·¸ë£¹ì´ 2ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤")
        
        # ANOVA
        f_stat, p_value = stats.f_oneway(*group_values.values())
        
        # ê·¸ë£¹ë³„ í†µê³„
        group_stats = {}
        for group_name, values in group_values.items():
            group_stats[group_name] = {
                'n': len(values),
                'mean': np.mean(values),
                'std': np.std(values),
                'ci_95': self._calculate_confidence_interval(values, confidence=0.95)
            }
        
        return {
            'f_statistic': f_stat,
            'p_value': p_value,
            'significant': p_value < alpha,
            'group_stats': group_stats,
            'n_groups': len(group_values)
        }
    
    def _calculate_cohens_d(self, group1: np.ndarray, group2: np.ndarray) -> float:
        """
        Cohen's d ê³„ì‚°
        
        ì—°êµ¬ ê·¼ê±°:
        - Cohen (1988) ê¸°ì¤€
        - d = (M1 - M2) / pooled_std
        
        í•´ì„:
        - |d| < 0.2: ì‘ì€ íš¨ê³¼
        - 0.2 â‰¤ |d| < 0.5: ì¤‘ê°„ íš¨ê³¼
        - 0.5 â‰¤ |d| < 0.8: í° íš¨ê³¼
        - |d| â‰¥ 0.8: ë§¤ìš° í° íš¨ê³¼
        """
        n1, n2 = len(group1), len(group2)
        mean1, mean2 = np.mean(group1), np.mean(group2)
        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
        
        # Pooled standard deviation
        pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))
        
        if pooled_std == 0:
            return 0.0
        
        cohens_d = (mean1 - mean2) / pooled_std
        
        return cohens_d
    
    def _interpret_effect_size(self, cohens_d: float) -> str:
        """íš¨ê³¼ í¬ê¸° í•´ì„"""
        abs_d = abs(cohens_d)
        
        if abs_d < 0.2:
            return "ì‘ì€ íš¨ê³¼ (negligible)"
        elif abs_d < 0.5:
            return "ì¤‘ê°„ íš¨ê³¼ (small)"
        elif abs_d < 0.8:
            return "í° íš¨ê³¼ (medium)"
        else:
            return "ë§¤ìš° í° íš¨ê³¼ (large)"
    
    def _calculate_confidence_interval(self,
                                       values: np.ndarray,
                                       confidence: float = 0.95) -> Tuple[float, float]:
        """ì‹ ë¢°êµ¬ê°„ ê³„ì‚°"""
        if len(values) < 2:
            return (values[0], values[0]) if len(values) == 1 else (0.0, 0.0)
        
        mean = np.mean(values)
        std = np.std(values, ddof=1)
        n = len(values)
        
        # t-ë¶„í¬ ì‚¬ìš©
        t_critical = stats.t.ppf((1 + confidence) / 2, df=n - 1)
        margin = t_critical * (std / np.sqrt(n))
        
        return (mean - margin, mean + margin)
    
    def _calculate_confidence_interval_diff(self,
                                           group1: np.ndarray,
                                           group2: np.ndarray,
                                           confidence: float = 0.95) -> Tuple[float, float]:
        """ë‘ ê·¸ë£¹ í‰ê·  ì°¨ì´ì˜ ì‹ ë¢°êµ¬ê°„"""
        mean1, mean2 = np.mean(group1), np.mean(group2)
        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
        n1, n2 = len(group1), len(group2)
        
        # í‘œì¤€ ì˜¤ì°¨
        se = np.sqrt((std1**2 / n1) + (std2**2 / n2))
        
        # ììœ ë„ (Welch's correction)
        df = ((std1**2 / n1 + std2**2 / n2)**2) / \
             ((std1**2 / n1)**2 / (n1 - 1) + (std2**2 / n2)**2 / (n2 - 1))
        df = max(1, int(df))
        
        # t-ë¶„í¬ ì‚¬ìš©
        t_critical = stats.t.ppf((1 + confidence) / 2, df=df)
        margin = t_critical * se
        
        mean_diff = mean1 - mean2
        
        return (mean_diff - margin, mean_diff + margin)
    
    def _extract_numeric_keys(self, result: Dict[str, Any]) -> List[str]:
        """ê²°ê³¼ì—ì„œ ìˆ«ì ê°’ í‚¤ ì¶”ì¶œ"""
        numeric_keys = []
        
        def extract_keys(obj, prefix=""):
            if isinstance(obj, dict):
                for key, value in obj.items():
                    full_key = f"{prefix}.{key}" if prefix else key
                    if isinstance(value, (int, float, np.number)):
                        numeric_keys.append(full_key)
                    elif isinstance(value, dict):
                        extract_keys(value, full_key)
                    elif isinstance(value, list):
                        if len(value) > 0 and isinstance(value[0], (int, float, np.number)):
                            numeric_keys.append(full_key)
        
        extract_keys(result)
        return numeric_keys
    
    def _get_nested_value(self, result: Dict[str, Any], key: str) -> Optional[float]:
        """ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°’ ì¶”ì¶œ"""
        keys = key.split('.')
        value = result
        
        for k in keys:
            if isinstance(value, dict) and k in value:
                value = value[k]
            else:
                return None
        
        if isinstance(value, (int, float, np.number)):
            return float(value)
        elif isinstance(value, list) and len(value) > 0:
            if isinstance(value[0], (int, float, np.number)):
                return float(np.mean(value))
        
        return None
    
    def generate_statistical_report(self,
                                   comparison_result: StatisticalResult,
                                   metric_name: str = "ì§€í‘œ") -> str:
        """
        í†µê³„ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            comparison_result: í†µê³„ ë¶„ì„ ê²°ê³¼
            metric_name: ì§€í‘œ ì´ë¦„
        
        Returns:
            ë¦¬í¬íŠ¸ ë¬¸ìì—´
        """
        report = f"""
{'=' * 70}
í†µê³„ ë¶„ì„ ê²°ê³¼: {metric_name}
{'=' * 70}

ê·¸ë£¹ ì •ë³´:
  - ê·¸ë£¹ 1: n = {comparison_result.n1}
  - ê·¸ë£¹ 2: n = {comparison_result.n2}
  - ììœ ë„: df = {comparison_result.df}

ì£¼ìš” í†µê³„:
  - í‰ê·  ì°¨ì´: {comparison_result.mean_diff:.4f}
  - í‘œì¤€í¸ì°¨ ì°¨ì´: {comparison_result.std_diff:.4f}

í†µê³„ ê²€ì •:
  - t-í†µê³„ëŸ‰: t({comparison_result.df}) = {comparison_result.t_statistic:.4f}
  - p-ê°’: p = {comparison_result.p_value:.6f}
  - ìœ ì˜ì„±: {'ìœ ì˜í•¨' if comparison_result.p_value < 0.05 else 'ìœ ì˜í•˜ì§€ ì•ŠìŒ'} 
    (Î± = 0.05)

íš¨ê³¼ í¬ê¸°:
  - Cohen's d: {comparison_result.cohens_d:.4f}
  - í•´ì„: {comparison_result.effect_size_interpretation}

ì‹ ë¢°êµ¬ê°„ (95%):
  - [{comparison_result.confidence_interval[0]:.4f}, 
     {comparison_result.confidence_interval[1]:.4f}]

{'=' * 70}
"""
        return report


# í¸ì˜ í•¨ìˆ˜
def seed_sweep(simulator_func, n_seeds: int = 100, **params) -> SeedSweepResult:
    """Seed Sweep ì‹¤í–‰"""
    analyzer = StatisticalAnalyzer()
    return analyzer.seed_sweep(simulator_func, n_seeds=n_seeds, **params)


def compare_groups(group1: List[Dict], group2: List[Dict], metric_key: str) -> StatisticalResult:
    """ë‘ ê·¸ë£¹ ë¹„êµ"""
    analyzer = StatisticalAnalyzer()
    return analyzer.compare_groups(group1, group2, metric_key)

